{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhrKKZqUfR8O",
        "outputId": "784b7c8e-f5aa-461f-8f9e-4c3492314266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Ambiente: Google Colab detectado.\n",
            "‚ö†Ô∏è Modelo 'pt_core_news_lg' n√£o encontrado. Tentando 'pt_core_news_md'...\n",
            "‚úÖ Modelo spaCy 'pt_core_news_md' carregado.\n",
            "‚ö†Ô∏è Vari√°vel de ambiente 'GROQ_API_KEY' n√£o encontrada.\n",
            "‚úÖ Chave da API da Groq carregada do Colab Secrets.\n",
            "‚úÖ Cliente da API Groq configurado.\n",
            "üîπ Carregando dados de: dataset_aumentado.csv\n",
            "üîπ Filtro aplicado: categorias v√°lidas = ['15', '16', '4']\n",
            "categoria\n",
            "15    402\n",
            "4      31\n",
            "16     22\n",
            "Name: count, dtype: int64\n",
            "üîπ Pre-processando textos com spaCy...\n",
            "\n",
            "üîπ Fold 1/5\n",
            "\n",
            "üîπ Fold 2/5\n"
          ]
        }
      ],
      "source": [
        "# ========================================================\n",
        "# üîπ CHyPS v3.1.3: Classifica√ß√£o H√≠brida com k-Fold=5 + Filtro 3 Classes + Gr√°fico Completo\n",
        "# ========================================================\n",
        "# Autor: Abra√£o Gualberto Naz√°rio (vers√£o atualizada por Gemini)\n",
        "# Data: Junho/2025\n",
        "# --------------------------------------------------------\n",
        "\n",
        "# --- SETUP DO AMBIENTE ---\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üîπ Ambiente: Google Colab detectado.\")\n",
        "    !pip install -q pandas openpyxl scikit-learn spacy openai matplotlib\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"üîπ Ambiente local detectado.\")\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- Setup spaCy ---\n",
        "try:\n",
        "    nlp = spacy.load('pt_core_news_lg')\n",
        "    print(\"‚úÖ Modelo spaCy 'pt_core_news_lg' carregado.\")\n",
        "except OSError:\n",
        "    print(\"‚ö†Ô∏è Modelo 'pt_core_news_lg' n√£o encontrado. Tentando 'pt_core_news_md'...\")\n",
        "    try:\n",
        "        nlp = spacy.load('pt_core_news_md')\n",
        "    except OSError:\n",
        "        print(\"üì• Baixando modelo 'pt_core_news_md'...\")\n",
        "        spacy.cli.download('pt_core_news_md')\n",
        "        nlp = spacy.load('pt_core_news_md')\n",
        "    print(\"‚úÖ Modelo spaCy 'pt_core_news_md' carregado.\")\n",
        "\n",
        "# --- Setup da API do LLM (Groq) ---\n",
        "api_key = os.getenv('GROQ_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"‚ö†Ô∏è Vari√°vel de ambiente 'GROQ_API_KEY' n√£o encontrada.\")\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        api_key = userdata.get('GROQ_API_KEY')\n",
        "        print(\"‚úÖ Chave da API da Groq carregada do Colab Secrets.\")\n",
        "    except Exception:\n",
        "        api_key = input(\"Insira sua chave de API da Groq manualmente: \")\n",
        "\n",
        "llm_client = OpenAI(api_key=api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
        "print(\"‚úÖ Cliente da API Groq configurado.\")\n",
        "\n",
        "# ========================================================\n",
        "# üîπ FUN√á√ïES DO ALGORITMO CHyPS\n",
        "# ========================================================\n",
        "\n",
        "def preprocess_with_spacy(text, nlp_model):\n",
        "    doc = nlp_model(str(text).lower())\n",
        "    lemmas = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
        "    return ' '.join(lemmas)\n",
        "\n",
        "def llm_classify_real(text_to_classify, llm_client, model_name):\n",
        "    system_prompt = \"\"\"\n",
        "    Voc√™ √© um especialista em classifica√ß√£o. Sua tarefa √© analisar o texto e classific√°-lo em UMA das seguintes categorias: '15', '16' ou '4'.\n",
        "    Sua resposta DEVE ser um objeto JSON: {\"classe\": \"15\", \"confianca\": 0.9}\n",
        "    \"\"\"\n",
        "    user_prompt = f'Texto para classificar:\\n---\\n{text_to_classify}\\n---\\nSua resposta em formato JSON:'\n",
        "    try:\n",
        "        response = llm_client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        json_response = json.loads(response.choices[0].message.content)\n",
        "        return str(json_response.get('classe', 'NI')), float(json_response.get('confianca', 0.0))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na chamada da API LLM: {e}\")\n",
        "        return 'NI', 0.0\n",
        "\n",
        "def chamar_llm_com_retry(text, tentativas=3, pausa=2):\n",
        "    for tentativa in range(tentativas):\n",
        "        try:\n",
        "            classe, confianca = llm_classify_real(text, llm_client, \"llama3-8b-8192\")\n",
        "            if classe != 'NI':\n",
        "                return classe, confianca\n",
        "        except Exception as e:\n",
        "            print(f\"Tentativa {tentativa+1}/{tentativas} falhou com erro: {e}\")\n",
        "        time.sleep(pausa)\n",
        "    return 'NI', 0.0\n",
        "\n",
        "def chyps_classify(texto_original, texto_limpo, rf_model, vectorizer, limiar_tau):\n",
        "    texto_tfidf = vectorizer.transform([texto_limpo])\n",
        "    rf_pred_proba = rf_model.predict_proba(texto_tfidf)\n",
        "    confianca_rf = np.max(rf_pred_proba)\n",
        "    predicao_rf = rf_model.classes_[np.argmax(rf_pred_proba)]\n",
        "    predicao_llm, confianca_llm = chamar_llm_com_retry(texto_original)\n",
        "    comprimento = len(texto_original.split())\n",
        "    W_rf, W_llm = (0.3, 0.7) if comprimento > limiar_tau else (0.7, 0.3)\n",
        "    score_rf = confianca_rf * W_rf\n",
        "    score_llm = confianca_llm * W_llm\n",
        "    return predicao_llm if score_llm > score_rf else predicao_rf\n",
        "\n",
        "def plotar_resultados(resultados_df):\n",
        "    resultados_df.plot(kind='bar', figsize=(14, 8))\n",
        "    plt.title('Comparativo Detalhado de M√©tricas por Modelo', fontsize=18, weight='bold')\n",
        "    plt.ylabel('Pontua√ß√£o', fontsize=14)\n",
        "    plt.xlabel('Modelo', fontsize=14)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.xticks(rotation=0, ha='center', fontsize=12)\n",
        "    plt.legend(title='M√©tricas', fontsize=11, loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('comparacao_detalhada_metricas.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# ========================================================\n",
        "# üîπ EXECU√á√ÉO PRINCIPAL (K-Fold=5)\n",
        "# ========================================================\n",
        "\n",
        "def main():\n",
        "    # --- Par√¢metros ---\n",
        "    NOME_DO_ARQUIVO = 'dataset_aumentado.csv'\n",
        "    K_FOLDS = 5\n",
        "    PAUSA_API = 0.5\n",
        "    LIMIAR_TAU = 20\n",
        "    AVERAGE_TYPE = 'weighted'\n",
        "\n",
        "    print(f\"üîπ Carregando dados de: {NOME_DO_ARQUIVO}\")\n",
        "    try:\n",
        "        df = pd.read_csv(NOME_DO_ARQUIVO)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå ERRO: Arquivo '{NOME_DO_ARQUIVO}' n√£o encontrado.\")\n",
        "        return\n",
        "    df['categoria'] = df['categoria'].astype(str)\n",
        "\n",
        "    CATEGORIAS_VALIDAS = ['15', '16', '4']\n",
        "    df = df[df['categoria'].isin(CATEGORIAS_VALIDAS)].copy()\n",
        "    print(\"üîπ Filtro aplicado: categorias v√°lidas =\", CATEGORIAS_VALIDAS)\n",
        "    print(df['categoria'].value_counts())\n",
        "\n",
        "    print(\"üîπ Pre-processando textos com spaCy...\")\n",
        "    df['texto_limpo'] = df['texto'].apply(lambda x: preprocess_with_spacy(x, nlp))\n",
        "\n",
        "    X_original = df['texto']\n",
        "    X_limpo = df['texto_limpo']\n",
        "    y = df['categoria']\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    metricas_rf, metricas_svm, metricas_chyps = [], [], []\n",
        "\n",
        "    fold = 1\n",
        "    for train_idx, test_idx in skf.split(X_limpo, y):\n",
        "        print(f\"\\nüîπ Fold {fold}/{K_FOLDS}\")\n",
        "        fold += 1\n",
        "\n",
        "        X_train_limpo, X_test_limpo = X_limpo.iloc[train_idx], X_limpo.iloc[test_idx]\n",
        "        X_train_original, X_test_original = X_original.iloc[train_idx], X_original.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "        X_train_tfidf = vectorizer.fit_transform(X_train_limpo)\n",
        "        X_test_tfidf = vectorizer.transform(X_test_limpo)\n",
        "\n",
        "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "        rf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        svm_model = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced')\n",
        "        svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        y_pred_rf = rf_model.predict(X_test_tfidf)\n",
        "        y_pred_svm = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "        y_pred_chyps = []\n",
        "        for texto_orig, texto_limpo in zip(X_test_original, X_test_limpo):\n",
        "            pred = chyps_classify(texto_orig, texto_limpo, rf_model, vectorizer, LIMIAR_TAU)\n",
        "            y_pred_chyps.append(pred)\n",
        "            time.sleep(PAUSA_API)\n",
        "\n",
        "        for metricas, y_pred in zip(\n",
        "            [metricas_rf, metricas_svm, metricas_chyps],\n",
        "            [y_pred_rf, y_pred_svm, y_pred_chyps]\n",
        "        ):\n",
        "            metricas.append({\n",
        "                'Acur√°cia': accuracy_score(y_test, y_pred),\n",
        "                'Precis√£o': precision_score(y_test, y_pred, average=AVERAGE_TYPE, zero_division=0),\n",
        "                'Recall': recall_score(y_test, y_pred, average=AVERAGE_TYPE, zero_division=0),\n",
        "                'F1-Score': f1_score(y_test, y_pred, average=AVERAGE_TYPE, zero_division=0)\n",
        "            })\n",
        "\n",
        "    resultados_df = pd.DataFrame({\n",
        "        'Modelo': ['Random Forest', 'SVM', 'CHyPS'],\n",
        "        'Acur√°cia': [np.mean([m['Acur√°cia'] for m in metricas_rf]), np.mean([m['Acur√°cia'] for m in metricas_svm]), np.mean([m['Acur√°cia'] for m in metricas_chyps])],\n",
        "        'Precis√£o': [np.mean([m['Precis√£o'] for m in metricas_rf]), np.mean([m['Precis√£o'] for m in metricas_svm]), np.mean([m['Precis√£o'] for m in metricas_chyps])],\n",
        "        'Recall': [np.mean([m['Recall'] for m in metricas_rf]), np.mean([m['Recall'] for m in metricas_svm]), np.mean([m['Recall'] for m in metricas_chyps])],\n",
        "        'F1-Score': [np.mean([m['F1-Score'] for m in metricas_rf]), np.mean([m['F1-Score'] for m in metricas_svm]), np.mean([m['F1-Score'] for m in metricas_chyps])]\n",
        "    }).set_index('Modelo')\n",
        "\n",
        "    print(\"\\nüìä RESULTADOS FINAIS (M√©dia 5 folds)\")\n",
        "    print(resultados_df)\n",
        "\n",
        "    plotar_resultados(resultados_df)\n",
        "    resultados_df.to_csv('resultados_chyps_kfold_completo.csv')\n",
        "\n",
        "    print(\"\\n‚úÖ Execu√ß√£o completa com gr√°fico completo (v3.1.3). üöÄ\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset manualmente s√≥ para analisar as classes\n",
        "df = pd.read_csv('dataset_aumentado.csv')\n",
        "df['categoria'] = df['categoria'].astype(str)\n",
        "\n",
        "# Ver quantos exemplos tem por classe\n",
        "classe_counts = df['categoria'].value_counts()\n",
        "print(\"Contagem de exemplos por classe:\")\n",
        "print(classe_counts)\n"
      ],
      "metadata": {
        "id": "YzdZkBprzhp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checar quantos exemplos tem por classe\n",
        "classe_counts = df['categoria'].value_counts()\n",
        "print(\"Contagem de exemplos por classe:\")\n",
        "print(classe_counts)"
      ],
      "metadata": {
        "id": "qmK1z0EegB4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}