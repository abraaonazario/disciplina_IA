{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "# üîπ CHyPS v2.5: Classifica√ß√£o H√≠brida (Vers√£o com Corre√ß√£o R√°pida)\n",
        "# ========================================================\n",
        "# Autor: Abra√£o Gualberto Naz√°rio\n",
        "# Orienta√ß√£o e Revis√£o Final: Gemini\n",
        "# Data: 21/06/2025\n",
        "# Nota da Vers√£o: Removido 'stratify=y' para garantir a execu√ß√£o com qualquer dataset.\n",
        "# --------------------------------------------------------\n",
        "\n",
        "# --- SETUP DO AMBIENTE ---\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üîπ Ambiente: Google Colab detectado.\")\n",
        "    # Instala libs no Colab\n",
        "    !pip install -q pandas openpyxl scikit-learn spacy openai matplotlib\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"üîπ Ambiente local detectado.\")\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- Setup spaCy ---\n",
        "try:\n",
        "    nlp = spacy.load('pt_core_news_lg')\n",
        "    print(\"‚úÖ Modelo spaCy 'pt_core_news_lg' carregado.\")\n",
        "except OSError:\n",
        "    print(\"‚ö†Ô∏è Modelo 'pt_core_news_lg' n√£o encontrado. Tentando 'pt_core_news_md'...\")\n",
        "    try:\n",
        "        nlp = spacy.load('pt_core_news_md')\n",
        "    except OSError:\n",
        "        print(\"üì• Baixando modelo 'pt_core_news_md'...\")\n",
        "        spacy.cli.download('pt_core_news_md')\n",
        "        nlp = spacy.load('pt_core_news_md')\n",
        "    print(\"‚úÖ Modelo spaCy 'pt_core_news_md' carregado.\")\n",
        "\n",
        "# --- Setup da API do LLM (Groq) ---\n",
        "api_key = os.getenv('GROQ_API_KEY')\n",
        "if not api_key:\n",
        "    print(\"‚ö†Ô∏è Vari√°vel de ambiente 'GROQ_API_KEY' n√£o encontrada.\")\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        api_key = userdata.get('GROQ_API_KEY')\n",
        "        print(\"‚úÖ Chave da API da Groq carregada do Colab Secrets.\")\n",
        "    except Exception:\n",
        "        api_key = input(\"Insira sua chave de API da Groq manualmente: \")\n",
        "\n",
        "llm_client = OpenAI(api_key=api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
        "print(\"‚úÖ Cliente da API Groq configurado.\")\n",
        "\n",
        "# ========================================================\n",
        "# üîπ FUN√á√ïES DO ALGORITMO CHyPS\n",
        "# ========================================================\n",
        "\n",
        "def preprocess_with_spacy(text, nlp_model):\n",
        "    doc = nlp_model(str(text).lower())\n",
        "    lemmas = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
        "    return ' '.join(lemmas)\n",
        "\n",
        "def llm_classify_real(text_to_classify, llm_client, model_name):\n",
        "    system_prompt = \"\"\"\n",
        "    Voc√™ √© um especialista em classifica√ß√£o. Sua tarefa √© analisar o texto e classific√°-lo em UMA das seguintes categorias: '15' (Terra/Agr√°rio), '16' (Paz/Acordos) ou '4' (Educa√ß√£o).\n",
        "    Sua resposta DEVE ser um objeto JSON com dois campos: \"classe\" (o n√∫mero da categoria como string) e \"confianca\" (um n√∫mero de 0.0 a 1.0 representando sua certeza).\n",
        "    Exemplo de resposta v√°lida: {\"classe\": \"15\", \"confianca\": 0.9}\n",
        "    \"\"\"\n",
        "    user_prompt = f'Texto para classificar:\\n---\\n{text_to_classify}\\n---\\nSua resposta em formato JSON:'\n",
        "    try:\n",
        "        response = llm_client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=0,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        json_response = json.loads(response.choices[0].message.content)\n",
        "        return str(json_response.get('classe', 'NI')), float(json_response.get('confianca', 0.0))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na chamada da API LLM: {e}\")\n",
        "        return 'NI', 0.0\n",
        "\n",
        "def chamar_llm_com_retry(text, tentativas=3, pausa=2):\n",
        "    for tentativa in range(tentativas):\n",
        "        try:\n",
        "            classe, confianca = llm_classify_real(text, llm_client, \"llama3-8b-8192\")\n",
        "            if classe != 'NI':\n",
        "                return classe, confianca\n",
        "        except Exception as e:\n",
        "            print(f\"Tentativa {tentativa+1}/{tentativas} falhou com erro: {e}\")\n",
        "        time.sleep(pausa)\n",
        "    return 'NI', 0.0\n",
        "\n",
        "def chyps_classify(texto_original, texto_limpo, rf_model, vectorizer, limiar_tau):\n",
        "    texto_tfidf = vectorizer.transform([texto_limpo])\n",
        "    rf_pred_proba = rf_model.predict_proba(texto_tfidf)\n",
        "    confianca_rf = np.max(rf_pred_proba)\n",
        "    predicao_rf = rf_model.classes_[np.argmax(rf_pred_proba)]\n",
        "    predicao_llm, confianca_llm = chamar_llm_com_retry(texto_original)\n",
        "    comprimento = len(texto_original.split())\n",
        "    W_rf, W_llm = (0.3, 0.7) if comprimento > limiar_tau else (0.7, 0.3)\n",
        "    score_rf = confianca_rf * W_rf\n",
        "    score_llm = confianca_llm * W_llm\n",
        "    return predicao_llm if score_llm > score_rf else predicao_rf\n",
        "\n",
        "def plotar_resultados(resultados_df):\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    ax = resultados_df.plot(kind='bar', figsize=(14, 8), width=0.8, colormap='viridis')\n",
        "    plt.title('An√°lise Comparativa de Desempenho', fontsize=18, weight='bold')\n",
        "    plt.ylabel('Pontua√ß√£o', fontsize=14)\n",
        "    plt.xlabel('Modelo', fontsize=14)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.xticks(rotation=0, ha='center', fontsize=12)\n",
        "    plt.legend(title='M√©tricas', fontsize=11, loc='upper left')\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f'{p.get_height():.3f}', (p.get_x() + p.get_width()/2, p.get_height()),\n",
        "                      ha='center', va='bottom', fontsize=10, color='black')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('comparacao_desempenho_final.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# ========================================================\n",
        "# üîπ EXECU√á√ÉO PRINCIPAL\n",
        "# ========================================================\n",
        "\n",
        "def main():\n",
        "    # --- Par√¢metros ---\n",
        "    NOME_DO_ARQUIVO = 'dataset_aumentado.csv'\n",
        "    PAUSA_API = 0.5\n",
        "    LIMIAR_TAU = 15\n",
        "    AVERAGE_TYPE = 'weighted'\n",
        "\n",
        "    # --- 1. Carga e Preparo dos Dados ---\n",
        "    print(f\"üîπ Carregando dados de: {NOME_DO_ARQUIVO}\")\n",
        "    try:\n",
        "        df = pd.read_csv(NOME_DO_ARQUIVO)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå ERRO: Arquivo '{NOME_DO_ARQUIVO}' n√£o encontrado. Fa√ßa o upload para o ambiente do Colab.\")\n",
        "        return\n",
        "    df['categoria'] = df['categoria'].astype(str)\n",
        "\n",
        "    # --- 2. Pr√©-processamento de Texto ---\n",
        "    print(\"üîπ Pr√©-processando textos com spaCy...\")\n",
        "    df['texto_limpo'] = df['texto'].apply(lambda x: preprocess_with_spacy(x, nlp))\n",
        "    print(\"‚úÖ Pr√©-processamento conclu√≠do.\")\n",
        "\n",
        "    # --- 3. Divis√£o de Dados e Vetoriza√ß√£o ---\n",
        "    X_original = df['texto']\n",
        "    X_limpo = df['texto_limpo']\n",
        "    y = df['categoria']\n",
        "    indices = df.index\n",
        "\n",
        "    # === CORRE√á√ÉO APLICADA (Op√ß√£o 1 - R√°pida) ===\n",
        "    # O par√¢metro 'stratify=y' foi removido para evitar o ValueError e garantir a execu√ß√£o.\n",
        "    X_train_limpo, X_test_limpo, y_train, y_test, indices_train, indices_test = train_test_split(\n",
        "        X_limpo, y, indices, test_size=0.3, random_state=42\n",
        "    )\n",
        "    X_test_original = X_original.loc[indices_test]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train_limpo)\n",
        "    X_test_tfidf = vectorizer.transform(X_test_limpo)\n",
        "\n",
        "    # --- 4. Treinamento dos Modelos de Base ---\n",
        "    print(\"üîπ Treinando modelos de base...\")\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "    rf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    svm_model = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced')\n",
        "    svm_model.fit(X_train_tfidf, y_train)\n",
        "    print(\"‚úÖ Modelos de base treinados.\")\n",
        "\n",
        "    # --- 5. Avalia√ß√£o dos Modelos ---\n",
        "    resultados = []\n",
        "\n",
        "    # Avalia√ß√£o do RF\n",
        "    y_pred_rf = rf_model.predict(X_test_tfidf)\n",
        "    resultados.append({\n",
        "        'Modelo': 'Random Forest', 'Acur√°cia': accuracy_score(y_test, y_pred_rf),\n",
        "        'Precis√£o': precision_score(y_test, y_pred_rf, average=AVERAGE_TYPE, zero_division=0),\n",
        "        'Recall': recall_score(y_test, y_pred_rf, average=AVERAGE_TYPE, zero_division=0),\n",
        "        'F1-Score': f1_score(y_test, y_pred_rf, average=AVERAGE_TYPE, zero_division=0)\n",
        "    })\n",
        "\n",
        "    # Avalia√ß√£o do SVM\n",
        "    y_pred_svm = svm_model.predict(X_test_tfidf)\n",
        "    resultados.append({\n",
        "        'Modelo': 'SVM', 'Acur√°cia': accuracy_score(y_test, y_pred_svm),\n",
        "        'Precis√£o': precision_score(y_test, y_pred_svm, average=AVERAGE_TYPE, zero_division=0),\n",
        "        'Recall': recall_score(y_test, y_pred_svm, average=AVERAGE_TYPE, zero_division=0),\n",
        "        'F1-Score': f1_score(y_test, y_pred_svm, average=AVERAGE_TYPE, zero_division=0)\n",
        "    })\n",
        "\n",
        "    # Avalia√ß√£o do CHyPS\n",
        "    print(\"üîπ Avaliando o CHyPS...\")\n",
        "    y_pred_chyps = []\n",
        "    for texto_original, texto_limpo in zip(X_test_original, X_test_limpo):\n",
        "        pred = chyps_classify(texto_original, texto_limpo, rf_model, vectorizer, LIMIAR_TAU)\n",
        "        y_pred_chyps.append(pred)\n",
        "        time.sleep(PAUSA_API)\n",
        "\n",
        "    resultados.append({\n",
        "        'Modelo': 'CHyPS', 'Acur√°cia': accuracy_score(y_test, y_pred_chyps),\n",
        "        'Precis√£o': precision_score(y_test, y_pred_chyps, average=AVERAGE_TYPE, zero_division=0),\n",
        "        'Recall': recall_score(y_test, y_pred_chyps, average=AVERAGE_TYPE, zero_division=0),\n",
        "        'F1-Score': f1_score(y_test, y_pred_chyps, average=AVERAGE_TYPE, zero_division=0)\n",
        "    })\n",
        "\n",
        "    # --- 6. Apresenta√ß√£o dos Resultados ---\n",
        "    resultados_df = pd.DataFrame(resultados).set_index('Modelo')\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"üìä RESULTADOS FINAIS üìä\")\n",
        "    print(\"=\"*40)\n",
        "    print(resultados_df)\n",
        "\n",
        "    plotar_resultados(resultados_df)\n",
        "\n",
        "    print(\"üîπ Salvando resultados em CSV...\")\n",
        "    resultados_df.to_csv('resultados_chyps.csv')\n",
        "\n",
        "    print(\"üîπ Gerando Matriz de Confus√£o para o CHyPS...\")\n",
        "    all_classes = sorted(y.unique())\n",
        "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred_chyps, labels=all_classes, cmap='Blues')\n",
        "    plt.title('Matriz de Confus√£o - CHyPS')\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('matriz_confusao_chyps.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n‚úÖ Fim da execu√ß√£o üöÄ\")\n",
        "\n",
        "# Ponto de entrada do script\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4LuEIKLu6UH",
        "outputId": "4f4acf81-8e1a-4d0d-c173-e67789b2a87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Ambiente: Google Colab detectado.\n",
            "‚ö†Ô∏è Modelo 'pt_core_news_lg' n√£o encontrado. Tentando 'pt_core_news_md'...\n",
            "‚úÖ Modelo spaCy 'pt_core_news_md' carregado.\n",
            "‚ö†Ô∏è Vari√°vel de ambiente 'GROQ_API_KEY' n√£o encontrada.\n",
            "‚úÖ Chave da API da Groq carregada do Colab Secrets.\n",
            "‚úÖ Cliente da API Groq configurado.\n",
            "üîπ Carregando dados de: dataset_aumentado.csv\n",
            "üîπ Pr√©-processando textos com spaCy...\n",
            "‚úÖ Pr√©-processamento conclu√≠do.\n",
            "üîπ Treinando modelos de base...\n",
            "‚úÖ Modelos de base treinados.\n",
            "üîπ Avaliando o CHyPS...\n"
          ]
        }
      ]
    }
  ]
}
